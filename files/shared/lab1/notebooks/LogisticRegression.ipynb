{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Hyperparameter Tuning using FPGAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to train and apply many accelerated sklearn models, with a k-fold cross validation and hyperparameter tuning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inaccel.sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression as LogisticRegressionCPU\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we'll be using the Modified NIST (*National Institute of Standards and Technology*) Digits dataset which is a set of **handwritten digits** derived from the NIST Special Database 19 and converted to a 28x28 pixel grayscale image format. Further information on the dataset's contents and conversion process is available at https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#mnist8m.\n",
    "Begin by featching the data from openml and inspecting the schema.\n",
    "<center>\n",
    "<img src=\"../img/digits.png\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', return_X_y = True)\n",
    "\n",
    "features = StandardScaler()\n",
    "X = features.fit_transform(X)\n",
    "\n",
    "label = LabelEncoder()\n",
    "y = label.fit_transform(y)\n",
    "\n",
    "print(\"Data shape:\\tLabels: \" + str(y.shape) + \"\\tFeatures: \" + str(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Grid of Hyperparameters |\n",
    "| ----------------------- |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'max_iter': (75,),\n",
    "        'l1_ratio': (0.5, 0.7),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| FPGA Accelerated GridSearchCV |\n",
    "| ----------------------------- |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_accel=4)\n",
    "\n",
    "grid_search = GridSearchCV(lr, param_grid, scoring='accuracy', verbose=1, cv=3, n_jobs=4, pre_dispatch = '4 * n_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "grid_search.fit(X, y)\n",
    "elapsed_time = int((time() - start_time) * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done in {0}s\".format(elapsed_time))\n",
    "print(\"Best score: {0}\".format(grid_search.best_score_))\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(list(param_grid.keys())):\n",
    "    print(\"\\t{0}: {1}\".format(param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Logistic Regression\n",
    "In the next cell we validate the trained model using the produced coefficients to visualize its classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = grid_search.best_estimator_.coef_.copy()\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.suptitle('Classification vector for:', y=0.91, fontsize = 15)\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(len(np.unique(y))):\n",
    "    fig = plt.subplot(10, 10, i + 1)\n",
    "    fig.imshow(coef[i].reshape(28, 28), cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
    "    fig.set_xticks(())\n",
    "    fig.set_yticks(())\n",
    "    fig.set_title('Class %i' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|CPU GridSearchCV |\n",
    "| --------------- |\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrCPU = LogisticRegressionCPU(intercept_scaling=0)\n",
    "\n",
    "grid_searchCPU = GridSearchCV(lrCPU, param_grid, scoring='accuracy', verbose=1, cv=3, n_jobs=4, pre_dispatch = '4 * n_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timeCPU = time()\n",
    "grid_searchCPU.fit(X, y) \n",
    "elapsed_timeCPU = int((time() - start_timeCPU) * 100) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done in {0}s\".format(elapsed_timeCPU))  \n",
    "print(\"Best score: {0}\".format(grid_searchCPU.best_score_))  \n",
    "print(\"Best parameters set:\")  \n",
    "best_parameters = grid_searchCPU.best_estimator_.get_params()  \n",
    "for param_name in sorted(list(param_grid.keys())):  \n",
    "    print(\"\\t{0}: {1}\".format(param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = grid_searchCPU.best_estimator_.coef_.copy()\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.suptitle('Classification vector for:', y=0.91, fontsize = 15)\n",
    "scale = np.abs(coef).max()\n",
    "for i in range(len(np.unique(y))):\n",
    "    fig = plt.subplot(10, 10, i + 1)\n",
    "    fig.imshow(coef[i].reshape(28, 28), cmap=plt.cm.RdBu, vmin=-scale, vmax=scale)\n",
    "    fig.set_xticks(())\n",
    "    fig.set_yticks(())\n",
    "    fig.set_title('Class %i' % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Speedup Calculation |\n",
    "|---------------------|\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = int(elapsed_timeCPU / elapsed_time * 100) / 100\n",
    "print(\"Speedup: \" + str(speedup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
